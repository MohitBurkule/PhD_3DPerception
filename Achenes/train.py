import numpy as np 
import torch
from torch import nn
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import model as ourmodel
import dataset as dt

model  = ourmodel.Terminator(3,1).cuda()

lr = 1e-6

criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)


dataset = dt.Projections([484, 246,  23, 534, 434, 109, 595,  16, 332, 362, 766, 562,  50,
       593, 696, 444, 164, 349,  83, 233, 148, 748, 550, 314, 273, 400,
       223, 465, 620, 643, 479,  51, 438, 298,   5,  40, 690, 180, 258,
       715, 604, 381, 654, 129,   9, 170, 563,  48, 739, 354,   6, 708,
       568, 668, 188, 556, 432, 514, 277, 396,  13, 127, 502, 485,  39,
       721, 205, 531, 742, 752, 133,  96, 118, 645, 472, 491, 191, 653,
       650, 505, 442, 735, 574, 130, 336, 403, 382, 200, 243,  18, 441,
       634,  47, 738,  85, 309, 762, 232, 132, 120, 182, 275, 462, 305,
       576, 523, 508, 440, 585, 702, 288,  41, 473, 543, 268, 553, 529,
       647, 561, 207, 410, 421, 313,  71, 408, 745, 140,  35, 773, 740,
        32, 658, 777, 262, 692, 359, 124, 590, 136, 449, 471, 327, 662,
       758, 565, 294, 489, 236, 725, 761, 245, 520, 763, 214, 571, 460,
        21, 624, 644, 103, 158, 307, 481, 722, 369, 113, 424, 694, 488,
         7, 373,  19, 192, 197, 458, 348, 436, 235, 283, 716, 310, 224,
       446,  87, 368, 719, 198, 619, 704,  91, 753, 149, 331, 231, 569,
       165, 385, 584, 655, 635, 430, 326, 252, 456,  65, 106, 711, 616,
       174, 540, 609, 390,  74, 547, 587, 512, 138,  55, 466, 730, 338,
       768, 181, 193, 759, 765, 311, 210, 474,  68, 572, 714, 225, 376,
         3, 347, 339, 374, 361, 503, 379, 342, 542,  72, 215, 399, 638,
       370, 139, 732, 592, 295, 594, 554, 167, 717, 121, 249, 117, 451,
       287, 199, 420, 545, 211, 688, 625, 698, 681, 573,  77, 416, 712,
       480,  52,  66, 409, 247, 105, 467, 506, 404,  90, 559, 516, 319,
       447, 629, 486, 221, 335, 601, 292, 560, 452, 677,  93, 119, 477,
       727, 622, 598,  89, 183,  60, 358,  78, 457, 422, 450, 509, 110,
       693, 577, 189, 779,   8, 154, 204, 633, 728,  64, 651, 510, 530,
       468, 433, 684, 676, 202, 691, 535, 493, 267, 201, 352, 754,
       669, 350, 608, 378, 709, 184, 366,  26, 603, 663, 328, 407, 657,
       429, 680, 253, 172,  22, 731, 566, 599, 371, 323, 674, 525, 756,
       750, 764, 775, 652, 289, 212, 499, 114, 639, 219, 344, 209, 411,
        11, 551, 168, 122, 355, 176, 244, 367,  27, 401, 630, 380, 498,
       179, 578,  25, 734, 178, 656, 689, 387, 539,  70, 377, 723, 710,
       596, 575, 772, 171, 552, 536, 351, 443,  95, 357, 345,  99, 230,
       116, 483, 636, 217, 496, 659, 343,  62, 760, 101, 392, 778, 163,
       279, 153, 780, 329, 334, 537, 490,  38, 673, 751, 220,  53, 695,
       143,  84, 487, 398,  30, 259, 700, 151, 463, 216, 297, 306, 322,
       333, 144, 611,  43,  37, 237, 526, 128, 500, 303, 256, 687, 423,
       363, 239,   4, 705,  98, 610, 504, 265, 613, 769, 394, 703, 412,
       375, 581, 771,  45, 744, 131, 494,  28, 227, 672, 173, 606,
       291, 266, 272, 478, 445, 733,  63, 646,  82, 190, 194, 678, 513,
       126,  81, 186, 280, 746,  33, 261, 222, 312, 600, 341, 161, 617,
       147, 623,  46, 146, 402, 726, 666, 507, 229, 425, 464, 517, 665,
       455, 324, 632, 337, 580, 664, 736, 628, 248, 284, 729, 413, 428,
       196, 282, 642, 166, 107, 134, 426, 177, 169, 317, 459, 418,  88,
       203, 469, 515, 605, 260, 724, 234, 627, 353, 389,  86,  49,  24,
       579, 660, 301,  75, 741,  34, 251, 102, 618, 125, 270, 185, 475,
       263, 720, 533, 589,  97, 541, 521, 588, 250,  58,  10, 555, 679,
       365, 145, 318, 257, 640, 111, 544,  80, 372, 686,  42, 285, 774,
       308, 104, 532,  29, 384, 626, 393, 150,  15, 137,  56, 776,  12,
       340, 649, 683],True,720,190)


dataloader  = DataLoader(dataset, batch_size=2,shuffle=True, num_workers=2)

writer = SummaryWriter()
for epoch in range(0,450):
    lost = []
    for v in dataloader:
        input_tensor = v[0].cuda()
        target = v[1].cuda()
        output = model(input_tensor.float())
        loss = criterion(output.double().squeeze(1), target.double())
        # ===================backward====================
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        lost.append(loss.detach().cpu().item())
        del loss
        del output
        del input_tensor
        del target
    if(epoch%20 ==0):
         torch.save(model.state_dict(),"can_temp.ckpt")
    writer.add_scalar("Loss",np.array(lost).mean(0),epoch)
    
torch.save(model.state_dict(), "unet_trans.ckpt")


